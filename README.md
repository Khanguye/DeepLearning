# Deep Learning

**Summary**
---
Alphabet Soup data more than 34,000 organizations that have received various amounts of funding from Alphabet Soup over the years.
Within this dataset are a number of columns that capture metadata about each organization such as the following:

1. EIN and NAME—Identification columns
2. APPLICATION_TYPE—Alphabet Soup application type
3. AFFILIATION—Affiliated sector of industry
4. CLASSIFICATION—Government organization classification
5. USE_CASE—Use case for funding
6. ORGANIZATION—Organization type
7. STATUS—Active status
8. INCOME_AMT—Income classification
9. SPECIAL_CONSIDERATIONS—Special consideration for application
10. ASK_AMT—Funding amount requested
11. IS_SUCCESSFUL—Was the money used effectively

Using machine learning and neural network model building build a binary classifier that is capable of predicting whether or not an applicant will be successful 
if funded by Alphabet Soup using the features collected in the provided dataset.

**Objectives**
---
1. Import, analyze, clean, and preprocess a “real-world” classification dataset.
2. Select, design, and train a binary classification model of your choosing.
3. Optimize model training and input data to achieve desired model performance.

**Sources**
---
1. [charity_data.csv](charity_data.csv)
2. [AlphabetSoupChallenge.ipynb](AlphabetSoupChallenge.ipynb)

**Conclusion**

